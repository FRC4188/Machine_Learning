{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FRC4188/Machine_Learning/blob/efficientdet/EfficientDet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXjxdN44q9Mg"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khanhlvg/tflite_raspberry_pi/blob/main/object_detection/Train_custom_model_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRYjtwRZGBOI"
      },
      "source": [
        "# Setup\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install packages"
      ],
      "metadata": {
        "id": "ViBFsRLNHA88"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35BJmtVpAP_n",
        "outputId": "9e5a6b5a-aee3-4cf8-902c-571e0e9fdb3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 616 kB 4.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 234 kB 45.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 47.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 87 kB 6.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 840 kB 43.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 42.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 48.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 22.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 36.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 20.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 32.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 77 kB 3.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 47.7 MB 66 kB/s \n",
            "\u001b[K     |████████████████████████████████| 99 kB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 11.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 47.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 211 kB 43.5 MB/s \n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q tflite-model-maker\n",
        "!pip install -q tflite-support"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import dependencies"
      ],
      "metadata": {
        "id": "INGN-qdPHFOW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "l4QQTXHHATDS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tflite_model_maker.config import ExportFormat, QuantizationConfig\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import object_detector\n",
        "\n",
        "from tflite_support import metadata\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "from absl import logging\n",
        "logging.set_verbosity(logging.ERROR)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KWiPjZ-_HLr7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3g6aQvXsD78P"
      },
      "source": [
        "# Prepare Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Take various pictures of the object from different angles, lighting, and distances. The more variations that you give the algorithm, the better it will be able to detect it in various circumstances.\n",
        "\n",
        "2. Upload the pictures to a computer. If you're taking pictures with an iPhone, you will most likely need to convert its .heic format to .jpg. If this is the case, simply google \"heic to jpg converter\" and various programs will pop up for you. However, most of the online sites only allow you to convert up to 5 images at a time. You can download an app from one of the websites that will allow you to conver up to 20 images at a time. If you want to still use an iPhone but not go through the hassle, navigate to Settings>Camera>Formats and choose \"Most Compatible\". This will automatically take pictures in .jpeg form. \n",
        "\n",
        "3. Navigate to https://app.roboflow.com/ and create an account. This website is where we will label our images. Follow all the necessary steps to create an account. Once you have that, create a new project. Name the project. Name the annotation group a generic name for your object. For example, if I wanted to detect a Toyota, a Nissan, and a Ford vehicle, I would name the annotation group \"car brands\". Once you're inside your project, upload all the pictures you've taken. When they're done, click finish uploading. Then, there will be a pop-up that has a bar with the words \"train\", \"valid\", and \"test\". The numbers represents how the dataset will be split when it goes through the model. The model will train with the \"train\" picture and validate itself with the \"valid\" pictures. The \"test\" pictures will be shown to you at the end. In general, just go with the default splitting. \n",
        "\n",
        "4. Begin annotating. Click on the first image and draw a box around the object of interest. There will be a prompt at the top that will ask you to identify the object you just put a box around. For each different, object give it a different name. Once you've given it a name, click \"save\" or enter on your keyboard. Do this same process for all images in your dataset. If the object you're detection is generic enough, you may be able to use \"label assist\" on the sidebar. It will employ a mini-algorithm that will help you detect things in your images. \n",
        "\n",
        "5. Export your model version. Navigate out of the images by clicking the back arrow and then click \"Dataset\" on the sidebar. Generate a new version. You can add preprocessing steps in order to improve your training. Once you've chosen the desired steps, you can also choose augmentation steps. This will also assist in your training. Go to the next step and generate the model. When the version has finished generating, click on the version you just created and click \"Export\". On format, select \"Pascal VOC\". Also, select \"show download code\". Make sure \"Raw URL\" is selected. Copy the link into the parentheses and run."
      ],
      "metadata": {
        "id": "H226eesBHucH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir balls\n",
        "%cd balls\n",
        "!curl -L \"your-link-here\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rw5uA8i9rvov",
        "outputId": "33601a53-a972-423e-9581-271f16877ead"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/balls\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   886  100   886    0     0   1215      0 --:--:-- --:--:-- --:--:--  1213\n",
            "100  782k  100  782k    0     0   367k      0  0:00:02  0:00:02 --:--:-- 4228k\n",
            "Archive:  roboflow.zip\n",
            " extracting: README.dataset.txt      \n",
            " extracting: README.roboflow.txt     \n",
            "   creating: test/\n",
            " extracting: test/IMG_4881_jpg.rf.d2ee9ef0c5ff5f49ef484e086a71eedb.jpg  \n",
            " extracting: test/IMG_4881_jpg.rf.d2ee9ef0c5ff5f49ef484e086a71eedb.xml  \n",
            " extracting: test/IMG_4882_jpg.rf.881a2d3d803ba0dd6658827a5c47d950.jpg  \n",
            " extracting: test/IMG_4882_jpg.rf.881a2d3d803ba0dd6658827a5c47d950.xml  \n",
            " extracting: test/IMG_4883_jpg.rf.a5b69aa81b21c7f440afa9715a34cb43.jpg  \n",
            " extracting: test/IMG_4883_jpg.rf.a5b69aa81b21c7f440afa9715a34cb43.xml  \n",
            " extracting: test/IMG_4884_jpg.rf.ba31eb4724a409f68b174111003e1527.jpg  \n",
            " extracting: test/IMG_4884_jpg.rf.ba31eb4724a409f68b174111003e1527.xml  \n",
            " extracting: test/IMG_4885_jpg.rf.8d2dc11fdd89104c1e564ba59c809522.jpg  \n",
            " extracting: test/IMG_4885_jpg.rf.8d2dc11fdd89104c1e564ba59c809522.xml  \n",
            " extracting: test/IMG_4890_jpg.rf.00a83a743f489c737165396acf9f3707.jpg  \n",
            " extracting: test/IMG_4890_jpg.rf.00a83a743f489c737165396acf9f3707.xml  \n",
            " extracting: test/IMG_4891_jpg.rf.090bde07006bf2cad1a64ccc13ba84cd.jpg  \n",
            " extracting: test/IMG_4891_jpg.rf.090bde07006bf2cad1a64ccc13ba84cd.xml  \n",
            " extracting: test/IMG_4892_jpg.rf.f6a5414e78cf7d406c02153a27b8bafa.jpg  \n",
            " extracting: test/IMG_4892_jpg.rf.f6a5414e78cf7d406c02153a27b8bafa.xml  \n",
            " extracting: test/IMG_4893_jpg.rf.c34733d6f0c227179004c73d97b1a8b6.jpg  \n",
            " extracting: test/IMG_4893_jpg.rf.c34733d6f0c227179004c73d97b1a8b6.xml  \n",
            " extracting: test/IMG_4894_jpg.rf.ac36946c83e2a97c3f94a6e6bc1d4dc3.jpg  \n",
            " extracting: test/IMG_4894_jpg.rf.ac36946c83e2a97c3f94a6e6bc1d4dc3.xml  \n",
            "   creating: train/\n",
            " extracting: train/IMG_4831_jpg.rf.26b31b808a3c55395ba4c2837b6e8b6e.jpg  \n",
            " extracting: train/IMG_4831_jpg.rf.26b31b808a3c55395ba4c2837b6e8b6e.xml  \n",
            " extracting: train/IMG_4831_jpg.rf.dd69b24034e272cf1e44545d73941a4c.jpg  \n",
            " extracting: train/IMG_4831_jpg.rf.dd69b24034e272cf1e44545d73941a4c.xml  \n",
            " extracting: train/IMG_4832_jpg.rf.5566ff517959fb5625e63b49d0f515bd.jpg  \n",
            " extracting: train/IMG_4832_jpg.rf.5566ff517959fb5625e63b49d0f515bd.xml  \n",
            " extracting: train/IMG_4832_jpg.rf.a8a595d449b0fb8185a6f5fc2606e480.jpg  \n",
            " extracting: train/IMG_4832_jpg.rf.a8a595d449b0fb8185a6f5fc2606e480.xml  \n",
            " extracting: train/IMG_4833_jpg.rf.726b10b624d824fa25c33678eb0535a8.jpg  \n",
            " extracting: train/IMG_4833_jpg.rf.726b10b624d824fa25c33678eb0535a8.xml  \n",
            " extracting: train/IMG_4833_jpg.rf.b856141d9584d29e49f021c092ec009a.jpg  \n",
            " extracting: train/IMG_4833_jpg.rf.b856141d9584d29e49f021c092ec009a.xml  \n",
            " extracting: train/IMG_4834_jpg.rf.4ab6d61d7ea4d58dac0d0ddef78dfb55.jpg  \n",
            " extracting: train/IMG_4834_jpg.rf.4ab6d61d7ea4d58dac0d0ddef78dfb55.xml  \n",
            " extracting: train/IMG_4834_jpg.rf.dc4c63f02254036dcd92ece73877609d.jpg  \n",
            " extracting: train/IMG_4834_jpg.rf.dc4c63f02254036dcd92ece73877609d.xml  \n",
            " extracting: train/IMG_4835_jpg.rf.54e06e39608acc76498bd260a105602c.jpg  \n",
            " extracting: train/IMG_4835_jpg.rf.54e06e39608acc76498bd260a105602c.xml  \n",
            " extracting: train/IMG_4835_jpg.rf.d3918ecec65b35b9b25484cf93ce4920.jpg  \n",
            " extracting: train/IMG_4835_jpg.rf.d3918ecec65b35b9b25484cf93ce4920.xml  \n",
            " extracting: train/IMG_4836_jpg.rf.488344ce237388ace1883ac87560a049.jpg  \n",
            " extracting: train/IMG_4836_jpg.rf.488344ce237388ace1883ac87560a049.xml  \n",
            " extracting: train/IMG_4836_jpg.rf.78fbac05bc9bbf2ed1ea7fd4a12a7dfd.jpg  \n",
            " extracting: train/IMG_4836_jpg.rf.78fbac05bc9bbf2ed1ea7fd4a12a7dfd.xml  \n",
            " extracting: train/IMG_4837_jpg.rf.3e1e8c51fe7afa8339f23314436bb7f2.jpg  \n",
            " extracting: train/IMG_4837_jpg.rf.3e1e8c51fe7afa8339f23314436bb7f2.xml  \n",
            " extracting: train/IMG_4837_jpg.rf.afa93d23cf90efae945776911bb000df.jpg  \n",
            " extracting: train/IMG_4837_jpg.rf.afa93d23cf90efae945776911bb000df.xml  \n",
            " extracting: train/IMG_4838_jpg.rf.8d61323416ec779716c7f130dcfc0e99.jpg  \n",
            " extracting: train/IMG_4838_jpg.rf.8d61323416ec779716c7f130dcfc0e99.xml  \n",
            " extracting: train/IMG_4838_jpg.rf.d913fc5d091c5c729eb97f23ceac3a76.jpg  \n",
            " extracting: train/IMG_4838_jpg.rf.d913fc5d091c5c729eb97f23ceac3a76.xml  \n",
            " extracting: train/IMG_4839_jpg.rf.10a038a38eed53271298a922f0bc0f6d.jpg  \n",
            " extracting: train/IMG_4839_jpg.rf.10a038a38eed53271298a922f0bc0f6d.xml  \n",
            " extracting: train/IMG_4839_jpg.rf.79df9fbada49210ddaf3201bdea40fbd.jpg  \n",
            " extracting: train/IMG_4839_jpg.rf.79df9fbada49210ddaf3201bdea40fbd.xml  \n",
            " extracting: train/IMG_4840_jpg.rf.84f63b6d8f9fa797da36ae6bed7e95a5.jpg  \n",
            " extracting: train/IMG_4840_jpg.rf.84f63b6d8f9fa797da36ae6bed7e95a5.xml  \n",
            " extracting: train/IMG_4840_jpg.rf.8be50e92a2aee12115f93723381d1d3d.jpg  \n",
            " extracting: train/IMG_4840_jpg.rf.8be50e92a2aee12115f93723381d1d3d.xml  \n",
            " extracting: train/IMG_4841_jpg.rf.a885c2e69683ee474a1827fb68198f88.jpg  \n",
            " extracting: train/IMG_4841_jpg.rf.a885c2e69683ee474a1827fb68198f88.xml  \n",
            " extracting: train/IMG_4841_jpg.rf.d62be59e25d25aeab3f80102199f334a.jpg  \n",
            " extracting: train/IMG_4841_jpg.rf.d62be59e25d25aeab3f80102199f334a.xml  \n",
            " extracting: train/IMG_4846_jpg.rf.0a601f42b6eb60281cc52712d947455e.jpg  \n",
            " extracting: train/IMG_4846_jpg.rf.0a601f42b6eb60281cc52712d947455e.xml  \n",
            " extracting: train/IMG_4846_jpg.rf.b7d2b8d6e587921ad4a4536a8e0bdcfd.jpg  \n",
            " extracting: train/IMG_4846_jpg.rf.b7d2b8d6e587921ad4a4536a8e0bdcfd.xml  \n",
            " extracting: train/IMG_4847_jpg.rf.5367a42386ec64d8da11996e2142b1dd.jpg  \n",
            " extracting: train/IMG_4847_jpg.rf.5367a42386ec64d8da11996e2142b1dd.xml  \n",
            " extracting: train/IMG_4847_jpg.rf.921218e524c0f4227c75670af775434c.jpg  \n",
            " extracting: train/IMG_4847_jpg.rf.921218e524c0f4227c75670af775434c.xml  \n",
            " extracting: train/IMG_4848_jpg.rf.0e045a252381ee7c7b149c22d4db54d4.jpg  \n",
            " extracting: train/IMG_4848_jpg.rf.0e045a252381ee7c7b149c22d4db54d4.xml  \n",
            " extracting: train/IMG_4848_jpg.rf.d90b27f2ea456222385c8a46e70a0f52.jpg  \n",
            " extracting: train/IMG_4848_jpg.rf.d90b27f2ea456222385c8a46e70a0f52.xml  \n",
            " extracting: train/IMG_4849_jpg.rf.c6cabb60425f7185bb9dece9a3b20404.jpg  \n",
            " extracting: train/IMG_4849_jpg.rf.c6cabb60425f7185bb9dece9a3b20404.xml  \n",
            " extracting: train/IMG_4849_jpg.rf.c6fb63f5363cdc20eb2e7bb30b827ff4.jpg  \n",
            " extracting: train/IMG_4849_jpg.rf.c6fb63f5363cdc20eb2e7bb30b827ff4.xml  \n",
            " extracting: train/IMG_4850_jpg.rf.9f677aea0c263dbfee8b356c5efd4932.jpg  \n",
            " extracting: train/IMG_4850_jpg.rf.9f677aea0c263dbfee8b356c5efd4932.xml  \n",
            " extracting: train/IMG_4850_jpg.rf.c04053a7b556e81e0ba20573ae23891c.jpg  \n",
            " extracting: train/IMG_4850_jpg.rf.c04053a7b556e81e0ba20573ae23891c.xml  \n",
            " extracting: train/IMG_4851_jpg.rf.d8add1a7b2d0a8c4029c691ab20124bf.jpg  \n",
            " extracting: train/IMG_4851_jpg.rf.d8add1a7b2d0a8c4029c691ab20124bf.xml  \n",
            " extracting: train/IMG_4851_jpg.rf.edfd0d2af1fc01e6c1f460e463d4fddf.jpg  \n",
            " extracting: train/IMG_4851_jpg.rf.edfd0d2af1fc01e6c1f460e463d4fddf.xml  \n",
            " extracting: train/IMG_4852_jpg.rf.44f73525acab459de5b5c882f3c2636d.jpg  \n",
            " extracting: train/IMG_4852_jpg.rf.44f73525acab459de5b5c882f3c2636d.xml  \n",
            " extracting: train/IMG_4852_jpg.rf.5e6d38f2804d0fcbb53b3f1bd07f42fe.jpg  \n",
            " extracting: train/IMG_4852_jpg.rf.5e6d38f2804d0fcbb53b3f1bd07f42fe.xml  \n",
            " extracting: train/IMG_4853_jpg.rf.af1d8c452065c96285a79c1383541220.jpg  \n",
            " extracting: train/IMG_4853_jpg.rf.af1d8c452065c96285a79c1383541220.xml  \n",
            " extracting: train/IMG_4853_jpg.rf.ea8810efc10aa85fda832ac28888433a.jpg  \n",
            " extracting: train/IMG_4853_jpg.rf.ea8810efc10aa85fda832ac28888433a.xml  \n",
            " extracting: train/IMG_4854_jpg.rf.3ab9ec9474e9b75e710f63431afd2617.jpg  \n",
            " extracting: train/IMG_4854_jpg.rf.3ab9ec9474e9b75e710f63431afd2617.xml  \n",
            " extracting: train/IMG_4854_jpg.rf.e71d52b5b2f4fe7251880a7a805aeab6.jpg  \n",
            " extracting: train/IMG_4854_jpg.rf.e71d52b5b2f4fe7251880a7a805aeab6.xml  \n",
            " extracting: train/IMG_4855_jpg.rf.24febb4e12a70f7c285ba00a3ac677c9.jpg  \n",
            " extracting: train/IMG_4855_jpg.rf.24febb4e12a70f7c285ba00a3ac677c9.xml  \n",
            " extracting: train/IMG_4855_jpg.rf.3d0127b9263cb44f2d61313c285d3de8.jpg  \n",
            " extracting: train/IMG_4855_jpg.rf.3d0127b9263cb44f2d61313c285d3de8.xml  \n",
            " extracting: train/IMG_4856_jpg.rf.068806cce4e7228227f84c79d36af512.jpg  \n",
            " extracting: train/IMG_4856_jpg.rf.068806cce4e7228227f84c79d36af512.xml  \n",
            " extracting: train/IMG_4856_jpg.rf.b81175984609894dacaa67b4fa1c18d6.jpg  \n",
            " extracting: train/IMG_4856_jpg.rf.b81175984609894dacaa67b4fa1c18d6.xml  \n",
            " extracting: train/IMG_4857_jpg.rf.4856dd72866123faf1c1b3b17d19cb96.jpg  \n",
            " extracting: train/IMG_4857_jpg.rf.4856dd72866123faf1c1b3b17d19cb96.xml  \n",
            " extracting: train/IMG_4857_jpg.rf.d0813a34a7ea25a55413c01a2f7dd348.jpg  \n",
            " extracting: train/IMG_4857_jpg.rf.d0813a34a7ea25a55413c01a2f7dd348.xml  \n",
            " extracting: train/IMG_4858_jpg.rf.5de4e50eb68efb512c016c6d91b4b2cf.jpg  \n",
            " extracting: train/IMG_4858_jpg.rf.5de4e50eb68efb512c016c6d91b4b2cf.xml  \n",
            " extracting: train/IMG_4858_jpg.rf.b032fda49d164770130a79332c1bec30.jpg  \n",
            " extracting: train/IMG_4858_jpg.rf.b032fda49d164770130a79332c1bec30.xml  \n",
            " extracting: train/IMG_4859_jpg.rf.86aab53b70889bb5757b6a2fb163aad6.jpg  \n",
            " extracting: train/IMG_4859_jpg.rf.86aab53b70889bb5757b6a2fb163aad6.xml  \n",
            " extracting: train/IMG_4859_jpg.rf.b5ca910925240148c9a476d3923e888d.jpg  \n",
            " extracting: train/IMG_4859_jpg.rf.b5ca910925240148c9a476d3923e888d.xml  \n",
            " extracting: train/IMG_4860_jpg.rf.16644b82e90c53b00f49144613f93081.jpg  \n",
            " extracting: train/IMG_4860_jpg.rf.16644b82e90c53b00f49144613f93081.xml  \n",
            " extracting: train/IMG_4860_jpg.rf.180f9cb4bea2b80a9a3e44b7793096a8.jpg  \n",
            " extracting: train/IMG_4860_jpg.rf.180f9cb4bea2b80a9a3e44b7793096a8.xml  \n",
            " extracting: train/IMG_4861_jpg.rf.63448295193f701b03d25faf0867c97b.jpg  \n",
            " extracting: train/IMG_4861_jpg.rf.63448295193f701b03d25faf0867c97b.xml  \n",
            " extracting: train/IMG_4861_jpg.rf.e49e4acd6690278906bbf19ceaf0d89b.jpg  \n",
            " extracting: train/IMG_4861_jpg.rf.e49e4acd6690278906bbf19ceaf0d89b.xml  \n",
            " extracting: train/IMG_4862_jpg.rf.cb1cce3c7dcef83103a184cc21af978c.jpg  \n",
            " extracting: train/IMG_4862_jpg.rf.cb1cce3c7dcef83103a184cc21af978c.xml  \n",
            " extracting: train/IMG_4862_jpg.rf.f911f93c74b66160d9db37094e3bf82f.jpg  \n",
            " extracting: train/IMG_4862_jpg.rf.f911f93c74b66160d9db37094e3bf82f.xml  \n",
            " extracting: train/IMG_4863_jpg.rf.190015ae8ca1f1f3800326a8f5358204.jpg  \n",
            " extracting: train/IMG_4863_jpg.rf.190015ae8ca1f1f3800326a8f5358204.xml  \n",
            " extracting: train/IMG_4863_jpg.rf.f56b1bbcd07304a37d95a2d01cf6c6cb.jpg  \n",
            " extracting: train/IMG_4863_jpg.rf.f56b1bbcd07304a37d95a2d01cf6c6cb.xml  \n",
            " extracting: train/IMG_4864_jpg.rf.435f440c337c56b937f45645aac323e0.jpg  \n",
            " extracting: train/IMG_4864_jpg.rf.435f440c337c56b937f45645aac323e0.xml  \n",
            " extracting: train/IMG_4864_jpg.rf.96285c2d90cdd57fe80a69e981b03781.jpg  \n",
            " extracting: train/IMG_4864_jpg.rf.96285c2d90cdd57fe80a69e981b03781.xml  \n",
            " extracting: train/IMG_4865_jpg.rf.4b7848d2a536355f94c59d88657ee82a.jpg  \n",
            " extracting: train/IMG_4865_jpg.rf.4b7848d2a536355f94c59d88657ee82a.xml  \n",
            " extracting: train/IMG_4865_jpg.rf.f444e8d58bc171de421bd33ac7b1e9bf.jpg  \n",
            " extracting: train/IMG_4865_jpg.rf.f444e8d58bc171de421bd33ac7b1e9bf.xml  \n",
            " extracting: train/IMG_4866_jpg.rf.3d1f1b5a37033bb0377c13593745bab9.jpg  \n",
            " extracting: train/IMG_4866_jpg.rf.3d1f1b5a37033bb0377c13593745bab9.xml  \n",
            " extracting: train/IMG_4866_jpg.rf.b69301074e95dce3668f1bf03c5de6f0.jpg  \n",
            " extracting: train/IMG_4866_jpg.rf.b69301074e95dce3668f1bf03c5de6f0.xml  \n",
            " extracting: train/IMG_4867_jpg.rf.336a794745054a199fb61c1b5351569c.jpg  \n",
            " extracting: train/IMG_4867_jpg.rf.336a794745054a199fb61c1b5351569c.xml  \n",
            " extracting: train/IMG_4867_jpg.rf.ce43b5a0512bfdb420cae839585242bc.jpg  \n",
            " extracting: train/IMG_4867_jpg.rf.ce43b5a0512bfdb420cae839585242bc.xml  \n",
            " extracting: train/IMG_4868_jpg.rf.a7ec0e23db9febedf67e3e5bc8141c99.jpg  \n",
            " extracting: train/IMG_4868_jpg.rf.a7ec0e23db9febedf67e3e5bc8141c99.xml  \n",
            " extracting: train/IMG_4868_jpg.rf.d6089bc31864c6e2d5d34ddc224eb24c.jpg  \n",
            " extracting: train/IMG_4868_jpg.rf.d6089bc31864c6e2d5d34ddc224eb24c.xml  \n",
            " extracting: train/IMG_4872_jpg.rf.89f14105320f1899f985e7e20be1ebc0.jpg  \n",
            " extracting: train/IMG_4872_jpg.rf.89f14105320f1899f985e7e20be1ebc0.xml  \n",
            " extracting: train/IMG_4872_jpg.rf.ea9add1a950d22c92257c864fa5eaaa6.jpg  \n",
            " extracting: train/IMG_4872_jpg.rf.ea9add1a950d22c92257c864fa5eaaa6.xml  \n",
            " extracting: train/IMG_4873_jpg.rf.335596efe70db9ea1a48f8dd196e3cc4.jpg  \n",
            " extracting: train/IMG_4873_jpg.rf.335596efe70db9ea1a48f8dd196e3cc4.xml  \n",
            " extracting: train/IMG_4873_jpg.rf.faa85a849c3d5c2384341c5a8af4835f.jpg  \n",
            " extracting: train/IMG_4873_jpg.rf.faa85a849c3d5c2384341c5a8af4835f.xml  \n",
            " extracting: train/IMG_4874_jpg.rf.d9f01450a858ac7e9a1afcbc6bb08c0f.jpg  \n",
            " extracting: train/IMG_4874_jpg.rf.d9f01450a858ac7e9a1afcbc6bb08c0f.xml  \n",
            " extracting: train/IMG_4874_jpg.rf.eca9334ca1e4c016c784b846994e1b86.jpg  \n",
            " extracting: train/IMG_4874_jpg.rf.eca9334ca1e4c016c784b846994e1b86.xml  \n",
            " extracting: train/IMG_4875_jpg.rf.1bb6a5c5c31f68a3c2a74003bad4cc42.jpg  \n",
            " extracting: train/IMG_4875_jpg.rf.1bb6a5c5c31f68a3c2a74003bad4cc42.xml  \n",
            " extracting: train/IMG_4875_jpg.rf.25146c57f2dc1d809198bbac4aab9046.jpg  \n",
            " extracting: train/IMG_4875_jpg.rf.25146c57f2dc1d809198bbac4aab9046.xml  \n",
            " extracting: train/IMG_4876_jpg.rf.71c8b2d681c20829a9b7c264bc34665a.jpg  \n",
            " extracting: train/IMG_4876_jpg.rf.71c8b2d681c20829a9b7c264bc34665a.xml  \n",
            " extracting: train/IMG_4876_jpg.rf.93d418256a8d15f7c0334d49dd79b654.jpg  \n",
            " extracting: train/IMG_4876_jpg.rf.93d418256a8d15f7c0334d49dd79b654.xml  \n",
            " extracting: train/IMG_4877_jpg.rf.3fe3abcee710da33f08d3328e15f6a9e.jpg  \n",
            " extracting: train/IMG_4877_jpg.rf.3fe3abcee710da33f08d3328e15f6a9e.xml  \n",
            " extracting: train/IMG_4877_jpg.rf.ab79debc2ee4cac418f97129bd273152.jpg  \n",
            " extracting: train/IMG_4877_jpg.rf.ab79debc2ee4cac418f97129bd273152.xml  \n",
            " extracting: train/IMG_4878_jpg.rf.7bcb7276c3c6d17e8b314bf0f591c7a8.jpg  \n",
            " extracting: train/IMG_4878_jpg.rf.7bcb7276c3c6d17e8b314bf0f591c7a8.xml  \n",
            " extracting: train/IMG_4878_jpg.rf.8193faeaba170371903402e3fa3f74aa.jpg  \n",
            " extracting: train/IMG_4878_jpg.rf.8193faeaba170371903402e3fa3f74aa.xml  \n",
            " extracting: train/IMG_4879_jpg.rf.837bc1d922cd7dcb782feb449edc070b.jpg  \n",
            " extracting: train/IMG_4879_jpg.rf.837bc1d922cd7dcb782feb449edc070b.xml  \n",
            " extracting: train/IMG_4879_jpg.rf.f18cef760a9f41b91707bd8baa9153d1.jpg  \n",
            " extracting: train/IMG_4879_jpg.rf.f18cef760a9f41b91707bd8baa9153d1.xml  \n",
            " extracting: train/IMG_4880_jpg.rf.bc9b66b180eb82b7e04e7f52cf627cf9.jpg  \n",
            " extracting: train/IMG_4880_jpg.rf.bc9b66b180eb82b7e04e7f52cf627cf9.xml  \n",
            " extracting: train/IMG_4880_jpg.rf.bcb7acff768381e2649f2b5c76258bed.jpg  \n",
            " extracting: train/IMG_4880_jpg.rf.bcb7acff768381e2649f2b5c76258bed.xml  \n",
            "   creating: valid/\n",
            " extracting: valid/IMG_4886_jpg.rf.afee95b02ec02d2c2cd7b344f33f70f9.jpg  \n",
            " extracting: valid/IMG_4886_jpg.rf.afee95b02ec02d2c2cd7b344f33f70f9.xml  \n",
            " extracting: valid/IMG_4887--1-_jpg.rf.48d25f9338ffca9610254511213c0562.jpg  \n",
            " extracting: valid/IMG_4887--1-_jpg.rf.48d25f9338ffca9610254511213c0562.xml  \n",
            " extracting: valid/IMG_4887_jpg.rf.b53e1a8d7cba5fe6e762c1b409c18348.jpg  \n",
            " extracting: valid/IMG_4887_jpg.rf.b53e1a8d7cba5fe6e762c1b409c18348.xml  \n",
            " extracting: valid/IMG_4888_jpg.rf.4d5d07eccb49ab1cb99f978e350d03a3.jpg  \n",
            " extracting: valid/IMG_4888_jpg.rf.4d5d07eccb49ab1cb99f978e350d03a3.xml  \n",
            " extracting: valid/IMG_4889_jpg.rf.480fe900fbcf2f8b1e019f600b282506.jpg  \n",
            " extracting: valid/IMG_4889_jpg.rf.480fe900fbcf2f8b1e019f600b282506.xml  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yxh3KInCFeB-"
      },
      "source": [
        "## Train the object detection model\n",
        "\n",
        "### Step 1: Load the dataset\n",
        "\n",
        "* Images in `train_data` is used to train the custom object detection model.\n",
        "* Images in `val_data` is used to check if the model can generalize well to new images that it hasn't seen before.\n",
        "\n",
        "Rename the directories and labels as needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WiAahdsQAdT7"
      },
      "outputs": [],
      "source": [
        "train_data = object_detector.DataLoader.from_pascal_voc(\n",
        "    'balls/train',\n",
        "    'balls/train',\n",
        "    ['red ball', 'blue ball']\n",
        ")\n",
        "\n",
        "val_data = object_detector.DataLoader.from_pascal_voc(\n",
        "    'balls/valid',\n",
        "    'balls/valid',\n",
        "    ['red ball', 'blue ball']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNRhB8N7GHXj"
      },
      "source": [
        "### Step 2: Select a model architecture\n",
        "\n",
        "EfficientDet-Lite[0-4] are a family of mobile/IoT-friendly object detection models derived from the [EfficientDet](https://arxiv.org/abs/1911.09070) architecture.\n",
        "\n",
        "Here is the performance of each EfficientDet-Lite models compared to each others.\n",
        "\n",
        "| Model architecture | Size(MB)* | Latency(ms)** | Average Precision*** |\n",
        "|--------------------|-----------|---------------|----------------------|\n",
        "| EfficientDet-Lite0 | 4.4       | 146           | 25.69%               |\n",
        "| EfficientDet-Lite1 | 5.8       | 259           | 30.55%               |\n",
        "| EfficientDet-Lite2 | 7.2       | 396           | 33.97%               |\n",
        "| EfficientDet-Lite3 | 11.4      | 716           | 37.70%               |\n",
        "| EfficientDet-Lite4 | 19.9      | 1886          | 41.96%               |\n",
        "\n",
        "<i> * Size of the integer quantized models. <br/>\n",
        "** Latency measured on Raspberry Pi 4 using 4 threads on CPU. <br/>\n",
        "*** Average Precision is the mAP (mean Average Precision) on the COCO 2017 validation dataset.\n",
        "</i>\n",
        "\n",
        "In this notebook, we use EfficientDet-Lite0 to train our model. You can choose other model architectures depending on whether speed or accuracy is more important to you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GZOojrDHAY1J"
      },
      "outputs": [],
      "source": [
        "spec = model_spec.get('efficientdet_lite0')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aeDU4mIM4ft"
      },
      "source": [
        "# Step 3: Train the TensorFlow model with the training data.\n",
        "\n",
        "* Set `epochs = 20`, which means it will go through the training dataset 20 times. You can look at the validation accuracy during training and stop when you see validation loss (`val_loss`) stop decreasing to avoid overfitting.\n",
        "* Set `batch_size = 4` here so you will see that it takes 15 steps to go through the 62 images in the training dataset.\n",
        "* Set `train_whole_model=True` to fine-tune the whole model instead of just training the head layer to improve accuracy. The trade-off is that it may take longer to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MClfpsJAfda",
        "outputId": "da94ab35-cdf3-43b5-e2ee-812120184717"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "21/21 [==============================] - 59s 515ms/step - det_loss: 1.6329 - cls_loss: 1.0265 - box_loss: 0.0121 - reg_l2_loss: 0.0630 - loss: 1.6959 - learning_rate: 0.0065 - gradient_norm: 3.4571 - val_det_loss: 1.3476 - val_cls_loss: 0.8578 - val_box_loss: 0.0098 - val_reg_l2_loss: 0.0630 - val_loss: 1.4106\n",
            "Epoch 2/60\n",
            "21/21 [==============================] - 7s 352ms/step - det_loss: 1.1635 - cls_loss: 0.6803 - box_loss: 0.0097 - reg_l2_loss: 0.0630 - loss: 1.2265 - learning_rate: 0.0050 - gradient_norm: 4.8883 - val_det_loss: 1.0899 - val_cls_loss: 0.6865 - val_box_loss: 0.0081 - val_reg_l2_loss: 0.0630 - val_loss: 1.1529\n",
            "Epoch 3/60\n",
            "21/21 [==============================] - 7s 350ms/step - det_loss: 1.0200 - cls_loss: 0.5556 - box_loss: 0.0093 - reg_l2_loss: 0.0630 - loss: 1.0830 - learning_rate: 0.0050 - gradient_norm: 6.6295 - val_det_loss: 0.9051 - val_cls_loss: 0.5666 - val_box_loss: 0.0068 - val_reg_l2_loss: 0.0630 - val_loss: 0.9682\n",
            "Epoch 4/60\n",
            "21/21 [==============================] - 8s 374ms/step - det_loss: 0.9304 - cls_loss: 0.4767 - box_loss: 0.0091 - reg_l2_loss: 0.0631 - loss: 0.9934 - learning_rate: 0.0050 - gradient_norm: 6.4237 - val_det_loss: 0.8103 - val_cls_loss: 0.5256 - val_box_loss: 0.0057 - val_reg_l2_loss: 0.0631 - val_loss: 0.8734\n",
            "Epoch 5/60\n",
            "21/21 [==============================] - 13s 619ms/step - det_loss: 0.8079 - cls_loss: 0.4681 - box_loss: 0.0068 - reg_l2_loss: 0.0631 - loss: 0.8710 - learning_rate: 0.0049 - gradient_norm: 6.2691 - val_det_loss: 0.6566 - val_cls_loss: 0.4473 - val_box_loss: 0.0042 - val_reg_l2_loss: 0.0631 - val_loss: 0.7197\n",
            "Epoch 6/60\n",
            "21/21 [==============================] - 7s 349ms/step - det_loss: 0.6945 - cls_loss: 0.4012 - box_loss: 0.0059 - reg_l2_loss: 0.0632 - loss: 0.7576 - learning_rate: 0.0049 - gradient_norm: 5.3106 - val_det_loss: 0.6457 - val_cls_loss: 0.4568 - val_box_loss: 0.0038 - val_reg_l2_loss: 0.0632 - val_loss: 0.7089\n",
            "Epoch 7/60\n",
            "21/21 [==============================] - 8s 377ms/step - det_loss: 0.7950 - cls_loss: 0.4197 - box_loss: 0.0075 - reg_l2_loss: 0.0632 - loss: 0.8582 - learning_rate: 0.0049 - gradient_norm: 6.1271 - val_det_loss: 0.6175 - val_cls_loss: 0.3840 - val_box_loss: 0.0047 - val_reg_l2_loss: 0.0632 - val_loss: 0.6807\n",
            "Epoch 8/60\n",
            "21/21 [==============================] - 7s 350ms/step - det_loss: 0.6821 - cls_loss: 0.3727 - box_loss: 0.0062 - reg_l2_loss: 0.0632 - loss: 0.7453 - learning_rate: 0.0048 - gradient_norm: 5.0004 - val_det_loss: 0.5054 - val_cls_loss: 0.3294 - val_box_loss: 0.0035 - val_reg_l2_loss: 0.0632 - val_loss: 0.5686\n",
            "Epoch 9/60\n",
            "21/21 [==============================] - 7s 351ms/step - det_loss: 0.6290 - cls_loss: 0.3526 - box_loss: 0.0055 - reg_l2_loss: 0.0633 - loss: 0.6923 - learning_rate: 0.0047 - gradient_norm: 6.0403 - val_det_loss: 0.4894 - val_cls_loss: 0.3150 - val_box_loss: 0.0035 - val_reg_l2_loss: 0.0633 - val_loss: 0.5526\n",
            "Epoch 10/60\n",
            "21/21 [==============================] - 8s 388ms/step - det_loss: 0.5341 - cls_loss: 0.3152 - box_loss: 0.0044 - reg_l2_loss: 0.0633 - loss: 0.5974 - learning_rate: 0.0047 - gradient_norm: 5.1466 - val_det_loss: 0.5150 - val_cls_loss: 0.3381 - val_box_loss: 0.0035 - val_reg_l2_loss: 0.0633 - val_loss: 0.5783\n",
            "Epoch 11/60\n",
            "21/21 [==============================] - 7s 353ms/step - det_loss: 0.6413 - cls_loss: 0.3728 - box_loss: 0.0054 - reg_l2_loss: 0.0633 - loss: 0.7046 - learning_rate: 0.0046 - gradient_norm: 5.3863 - val_det_loss: 0.4525 - val_cls_loss: 0.2837 - val_box_loss: 0.0034 - val_reg_l2_loss: 0.0633 - val_loss: 0.5159\n",
            "Epoch 12/60\n",
            "21/21 [==============================] - 8s 377ms/step - det_loss: 0.5716 - cls_loss: 0.3346 - box_loss: 0.0047 - reg_l2_loss: 0.0633 - loss: 0.6350 - learning_rate: 0.0045 - gradient_norm: 4.6839 - val_det_loss: 0.5092 - val_cls_loss: 0.3084 - val_box_loss: 0.0040 - val_reg_l2_loss: 0.0634 - val_loss: 0.5726\n",
            "Epoch 13/60\n",
            "21/21 [==============================] - 7s 353ms/step - det_loss: 0.5360 - cls_loss: 0.2985 - box_loss: 0.0048 - reg_l2_loss: 0.0634 - loss: 0.5994 - learning_rate: 0.0045 - gradient_norm: 4.2640 - val_det_loss: 0.4480 - val_cls_loss: 0.2636 - val_box_loss: 0.0037 - val_reg_l2_loss: 0.0634 - val_loss: 0.5114\n",
            "Epoch 14/60\n",
            "21/21 [==============================] - 7s 351ms/step - det_loss: 0.6117 - cls_loss: 0.3549 - box_loss: 0.0051 - reg_l2_loss: 0.0634 - loss: 0.6751 - learning_rate: 0.0044 - gradient_norm: 5.0435 - val_det_loss: 0.3793 - val_cls_loss: 0.2447 - val_box_loss: 0.0027 - val_reg_l2_loss: 0.0634 - val_loss: 0.4427\n",
            "Epoch 15/60\n",
            "21/21 [==============================] - 8s 384ms/step - det_loss: 0.5456 - cls_loss: 0.3376 - box_loss: 0.0042 - reg_l2_loss: 0.0634 - loss: 0.6090 - learning_rate: 0.0043 - gradient_norm: 4.1931 - val_det_loss: 0.4700 - val_cls_loss: 0.3413 - val_box_loss: 0.0026 - val_reg_l2_loss: 0.0634 - val_loss: 0.5334\n",
            "Epoch 16/60\n",
            "21/21 [==============================] - 8s 377ms/step - det_loss: 0.4737 - cls_loss: 0.2864 - box_loss: 0.0037 - reg_l2_loss: 0.0634 - loss: 0.5371 - learning_rate: 0.0042 - gradient_norm: 4.4464 - val_det_loss: 0.4918 - val_cls_loss: 0.3623 - val_box_loss: 0.0026 - val_reg_l2_loss: 0.0634 - val_loss: 0.5552\n",
            "Epoch 17/60\n",
            "21/21 [==============================] - 7s 351ms/step - det_loss: 0.5439 - cls_loss: 0.2972 - box_loss: 0.0049 - reg_l2_loss: 0.0634 - loss: 0.6073 - learning_rate: 0.0041 - gradient_norm: 4.6227 - val_det_loss: 0.5345 - val_cls_loss: 0.3898 - val_box_loss: 0.0029 - val_reg_l2_loss: 0.0634 - val_loss: 0.5979\n",
            "Epoch 18/60\n",
            "21/21 [==============================] - 7s 352ms/step - det_loss: 0.4383 - cls_loss: 0.2431 - box_loss: 0.0039 - reg_l2_loss: 0.0634 - loss: 0.5018 - learning_rate: 0.0040 - gradient_norm: 3.7890 - val_det_loss: 0.5204 - val_cls_loss: 0.3850 - val_box_loss: 0.0027 - val_reg_l2_loss: 0.0634 - val_loss: 0.5839\n",
            "Epoch 19/60\n",
            "21/21 [==============================] - 7s 351ms/step - det_loss: 0.4762 - cls_loss: 0.2720 - box_loss: 0.0041 - reg_l2_loss: 0.0634 - loss: 0.5396 - learning_rate: 0.0039 - gradient_norm: 4.3826 - val_det_loss: 0.3391 - val_cls_loss: 0.2408 - val_box_loss: 0.0020 - val_reg_l2_loss: 0.0634 - val_loss: 0.4026\n",
            "Epoch 20/60\n",
            "21/21 [==============================] - 8s 409ms/step - det_loss: 0.4485 - cls_loss: 0.2676 - box_loss: 0.0036 - reg_l2_loss: 0.0634 - loss: 0.5119 - learning_rate: 0.0038 - gradient_norm: 3.4477 - val_det_loss: 0.4594 - val_cls_loss: 0.2678 - val_box_loss: 0.0038 - val_reg_l2_loss: 0.0634 - val_loss: 0.5229\n",
            "Epoch 21/60\n",
            "21/21 [==============================] - 7s 356ms/step - det_loss: 0.4513 - cls_loss: 0.2700 - box_loss: 0.0036 - reg_l2_loss: 0.0635 - loss: 0.5148 - learning_rate: 0.0037 - gradient_norm: 4.0840 - val_det_loss: 0.4149 - val_cls_loss: 0.2779 - val_box_loss: 0.0027 - val_reg_l2_loss: 0.0635 - val_loss: 0.4783\n",
            "Epoch 22/60\n",
            "21/21 [==============================] - 7s 353ms/step - det_loss: 0.4904 - cls_loss: 0.2686 - box_loss: 0.0044 - reg_l2_loss: 0.0635 - loss: 0.5539 - learning_rate: 0.0035 - gradient_norm: 4.4736 - val_det_loss: 0.3392 - val_cls_loss: 0.2217 - val_box_loss: 0.0023 - val_reg_l2_loss: 0.0635 - val_loss: 0.4027\n",
            "Epoch 23/60\n",
            "21/21 [==============================] - 7s 352ms/step - det_loss: 0.4569 - cls_loss: 0.2654 - box_loss: 0.0038 - reg_l2_loss: 0.0635 - loss: 0.5204 - learning_rate: 0.0034 - gradient_norm: 4.0609 - val_det_loss: 0.3755 - val_cls_loss: 0.2694 - val_box_loss: 0.0021 - val_reg_l2_loss: 0.0635 - val_loss: 0.4389\n",
            "Epoch 24/60\n",
            "21/21 [==============================] - 7s 353ms/step - det_loss: 0.4636 - cls_loss: 0.2726 - box_loss: 0.0038 - reg_l2_loss: 0.0635 - loss: 0.5270 - learning_rate: 0.0033 - gradient_norm: 4.2775 - val_det_loss: 0.3850 - val_cls_loss: 0.2945 - val_box_loss: 0.0018 - val_reg_l2_loss: 0.0635 - val_loss: 0.4484\n",
            "Epoch 25/60\n",
            "21/21 [==============================] - 8s 407ms/step - det_loss: 0.3874 - cls_loss: 0.2408 - box_loss: 0.0029 - reg_l2_loss: 0.0635 - loss: 0.4509 - learning_rate: 0.0032 - gradient_norm: 3.5672 - val_det_loss: 0.3651 - val_cls_loss: 0.2784 - val_box_loss: 0.0017 - val_reg_l2_loss: 0.0635 - val_loss: 0.4286\n",
            "Epoch 26/60\n",
            "21/21 [==============================] - 7s 356ms/step - det_loss: 0.3701 - cls_loss: 0.2216 - box_loss: 0.0030 - reg_l2_loss: 0.0635 - loss: 0.4336 - learning_rate: 0.0030 - gradient_norm: 3.7372 - val_det_loss: 0.3339 - val_cls_loss: 0.2493 - val_box_loss: 0.0017 - val_reg_l2_loss: 0.0635 - val_loss: 0.3974\n",
            "Epoch 27/60\n",
            "21/21 [==============================] - 7s 350ms/step - det_loss: 0.3678 - cls_loss: 0.2292 - box_loss: 0.0028 - reg_l2_loss: 0.0635 - loss: 0.4312 - learning_rate: 0.0029 - gradient_norm: 3.2020 - val_det_loss: 0.3415 - val_cls_loss: 0.2555 - val_box_loss: 0.0017 - val_reg_l2_loss: 0.0635 - val_loss: 0.4049\n",
            "Epoch 28/60\n",
            "21/21 [==============================] - 7s 353ms/step - det_loss: 0.3625 - cls_loss: 0.2235 - box_loss: 0.0028 - reg_l2_loss: 0.0635 - loss: 0.4259 - learning_rate: 0.0028 - gradient_norm: 3.0928 - val_det_loss: 0.2897 - val_cls_loss: 0.2037 - val_box_loss: 0.0017 - val_reg_l2_loss: 0.0635 - val_loss: 0.3532\n",
            "Epoch 29/60\n",
            "21/21 [==============================] - 8s 373ms/step - det_loss: 0.4836 - cls_loss: 0.2884 - box_loss: 0.0039 - reg_l2_loss: 0.0635 - loss: 0.5471 - learning_rate: 0.0026 - gradient_norm: 4.6815 - val_det_loss: 0.3425 - val_cls_loss: 0.2452 - val_box_loss: 0.0019 - val_reg_l2_loss: 0.0635 - val_loss: 0.4060\n",
            "Epoch 30/60\n",
            "21/21 [==============================] - 8s 389ms/step - det_loss: 0.4007 - cls_loss: 0.2324 - box_loss: 0.0034 - reg_l2_loss: 0.0635 - loss: 0.4642 - learning_rate: 0.0025 - gradient_norm: 3.2488 - val_det_loss: 0.2579 - val_cls_loss: 0.2088 - val_box_loss: 9.8165e-04 - val_reg_l2_loss: 0.0635 - val_loss: 0.3214\n",
            "Epoch 31/60\n",
            "21/21 [==============================] - 7s 352ms/step - det_loss: 0.3492 - cls_loss: 0.2167 - box_loss: 0.0027 - reg_l2_loss: 0.0635 - loss: 0.4127 - learning_rate: 0.0024 - gradient_norm: 3.3823 - val_det_loss: 0.2938 - val_cls_loss: 0.2248 - val_box_loss: 0.0014 - val_reg_l2_loss: 0.0635 - val_loss: 0.3573\n",
            "Epoch 32/60\n",
            "21/21 [==============================] - 7s 353ms/step - det_loss: 0.3797 - cls_loss: 0.2397 - box_loss: 0.0028 - reg_l2_loss: 0.0635 - loss: 0.4432 - learning_rate: 0.0022 - gradient_norm: 3.3915 - val_det_loss: 0.2987 - val_cls_loss: 0.2107 - val_box_loss: 0.0018 - val_reg_l2_loss: 0.0635 - val_loss: 0.3622\n",
            "Epoch 33/60\n",
            "21/21 [==============================] - 8s 378ms/step - det_loss: 0.3356 - cls_loss: 0.2162 - box_loss: 0.0024 - reg_l2_loss: 0.0635 - loss: 0.3991 - learning_rate: 0.0021 - gradient_norm: 3.0021 - val_det_loss: 0.2542 - val_cls_loss: 0.1931 - val_box_loss: 0.0012 - val_reg_l2_loss: 0.0635 - val_loss: 0.3177\n",
            "Epoch 34/60\n",
            "21/21 [==============================] - 7s 351ms/step - det_loss: 0.3561 - cls_loss: 0.2290 - box_loss: 0.0025 - reg_l2_loss: 0.0635 - loss: 0.4196 - learning_rate: 0.0020 - gradient_norm: 3.6681 - val_det_loss: 0.2876 - val_cls_loss: 0.2097 - val_box_loss: 0.0016 - val_reg_l2_loss: 0.0635 - val_loss: 0.3511\n",
            "Epoch 35/60\n",
            "21/21 [==============================] - 8s 385ms/step - det_loss: 0.3792 - cls_loss: 0.2371 - box_loss: 0.0028 - reg_l2_loss: 0.0635 - loss: 0.4427 - learning_rate: 0.0018 - gradient_norm: 3.5141 - val_det_loss: 0.3307 - val_cls_loss: 0.1984 - val_box_loss: 0.0026 - val_reg_l2_loss: 0.0635 - val_loss: 0.3942\n",
            "Epoch 36/60\n",
            "21/21 [==============================] - 7s 353ms/step - det_loss: 0.3274 - cls_loss: 0.2086 - box_loss: 0.0024 - reg_l2_loss: 0.0635 - loss: 0.3909 - learning_rate: 0.0017 - gradient_norm: 3.0522 - val_det_loss: 0.2766 - val_cls_loss: 0.1947 - val_box_loss: 0.0016 - val_reg_l2_loss: 0.0635 - val_loss: 0.3401\n",
            "Epoch 37/60\n",
            "21/21 [==============================] - 8s 375ms/step - det_loss: 0.3083 - cls_loss: 0.1916 - box_loss: 0.0023 - reg_l2_loss: 0.0635 - loss: 0.3718 - learning_rate: 0.0016 - gradient_norm: 2.5336 - val_det_loss: 0.2876 - val_cls_loss: 0.2079 - val_box_loss: 0.0016 - val_reg_l2_loss: 0.0635 - val_loss: 0.3512\n",
            "Epoch 38/60\n",
            "21/21 [==============================] - 7s 349ms/step - det_loss: 0.3043 - cls_loss: 0.1958 - box_loss: 0.0022 - reg_l2_loss: 0.0635 - loss: 0.3678 - learning_rate: 0.0015 - gradient_norm: 2.7454 - val_det_loss: 0.2567 - val_cls_loss: 0.1924 - val_box_loss: 0.0013 - val_reg_l2_loss: 0.0635 - val_loss: 0.3202\n",
            "Epoch 39/60\n",
            "21/21 [==============================] - 7s 352ms/step - det_loss: 0.3920 - cls_loss: 0.2356 - box_loss: 0.0031 - reg_l2_loss: 0.0635 - loss: 0.4555 - learning_rate: 0.0013 - gradient_norm: 3.4555 - val_det_loss: 0.2784 - val_cls_loss: 0.1948 - val_box_loss: 0.0017 - val_reg_l2_loss: 0.0635 - val_loss: 0.3419\n",
            "Epoch 40/60\n",
            "21/21 [==============================] - 8s 388ms/step - det_loss: 0.3409 - cls_loss: 0.2221 - box_loss: 0.0024 - reg_l2_loss: 0.0635 - loss: 0.4044 - learning_rate: 0.0012 - gradient_norm: 3.3133 - val_det_loss: 0.2645 - val_cls_loss: 0.1989 - val_box_loss: 0.0013 - val_reg_l2_loss: 0.0635 - val_loss: 0.3280\n",
            "Epoch 41/60\n",
            "21/21 [==============================] - 8s 359ms/step - det_loss: 0.3271 - cls_loss: 0.2107 - box_loss: 0.0023 - reg_l2_loss: 0.0635 - loss: 0.3906 - learning_rate: 0.0011 - gradient_norm: 3.1103 - val_det_loss: 0.2792 - val_cls_loss: 0.2132 - val_box_loss: 0.0013 - val_reg_l2_loss: 0.0635 - val_loss: 0.3427\n",
            "Epoch 42/60\n",
            "21/21 [==============================] - 8s 371ms/step - det_loss: 0.3215 - cls_loss: 0.2036 - box_loss: 0.0024 - reg_l2_loss: 0.0635 - loss: 0.3850 - learning_rate: 0.0010 - gradient_norm: 3.1176 - val_det_loss: 0.2605 - val_cls_loss: 0.2011 - val_box_loss: 0.0012 - val_reg_l2_loss: 0.0635 - val_loss: 0.3240\n",
            "Epoch 43/60\n",
            "21/21 [==============================] - 7s 346ms/step - det_loss: 0.3923 - cls_loss: 0.2326 - box_loss: 0.0032 - reg_l2_loss: 0.0635 - loss: 0.4558 - learning_rate: 9.0481e-04 - gradient_norm: 3.0628 - val_det_loss: 0.2611 - val_cls_loss: 0.1963 - val_box_loss: 0.0013 - val_reg_l2_loss: 0.0635 - val_loss: 0.3246\n",
            "Epoch 44/60\n",
            "21/21 [==============================] - 7s 353ms/step - det_loss: 0.3472 - cls_loss: 0.2253 - box_loss: 0.0024 - reg_l2_loss: 0.0635 - loss: 0.4107 - learning_rate: 8.0465e-04 - gradient_norm: 3.4745 - val_det_loss: 0.2790 - val_cls_loss: 0.2050 - val_box_loss: 0.0015 - val_reg_l2_loss: 0.0635 - val_loss: 0.3425\n",
            "Epoch 45/60\n",
            "21/21 [==============================] - 8s 381ms/step - det_loss: 0.3176 - cls_loss: 0.2036 - box_loss: 0.0023 - reg_l2_loss: 0.0635 - loss: 0.3811 - learning_rate: 7.0929e-04 - gradient_norm: 2.8874 - val_det_loss: 0.2659 - val_cls_loss: 0.2062 - val_box_loss: 0.0012 - val_reg_l2_loss: 0.0635 - val_loss: 0.3294\n",
            "Epoch 46/60\n",
            "21/21 [==============================] - 8s 384ms/step - det_loss: 0.3317 - cls_loss: 0.2188 - box_loss: 0.0023 - reg_l2_loss: 0.0635 - loss: 0.3952 - learning_rate: 6.1900e-04 - gradient_norm: 2.6800 - val_det_loss: 0.2552 - val_cls_loss: 0.1922 - val_box_loss: 0.0013 - val_reg_l2_loss: 0.0635 - val_loss: 0.3187\n",
            "Epoch 47/60\n",
            "21/21 [==============================] - 7s 357ms/step - det_loss: 0.3539 - cls_loss: 0.2257 - box_loss: 0.0026 - reg_l2_loss: 0.0635 - loss: 0.4174 - learning_rate: 5.3405e-04 - gradient_norm: 3.5021 - val_det_loss: 0.2607 - val_cls_loss: 0.1956 - val_box_loss: 0.0013 - val_reg_l2_loss: 0.0635 - val_loss: 0.3242\n",
            "Epoch 48/60\n",
            "21/21 [==============================] - 7s 352ms/step - det_loss: 0.4102 - cls_loss: 0.2625 - box_loss: 0.0030 - reg_l2_loss: 0.0635 - loss: 0.4736 - learning_rate: 4.5467e-04 - gradient_norm: 3.4569 - val_det_loss: 0.2418 - val_cls_loss: 0.1915 - val_box_loss: 0.0010 - val_reg_l2_loss: 0.0635 - val_loss: 0.3053\n",
            "Epoch 49/60\n",
            "21/21 [==============================] - 7s 351ms/step - det_loss: 0.3373 - cls_loss: 0.2091 - box_loss: 0.0026 - reg_l2_loss: 0.0635 - loss: 0.4008 - learning_rate: 3.8108e-04 - gradient_norm: 2.9416 - val_det_loss: 0.2490 - val_cls_loss: 0.1916 - val_box_loss: 0.0011 - val_reg_l2_loss: 0.0635 - val_loss: 0.3125\n",
            "Epoch 50/60\n",
            "21/21 [==============================] - 8s 410ms/step - det_loss: 0.3486 - cls_loss: 0.2118 - box_loss: 0.0027 - reg_l2_loss: 0.0635 - loss: 0.4121 - learning_rate: 3.1351e-04 - gradient_norm: 2.9588 - val_det_loss: 0.2593 - val_cls_loss: 0.1990 - val_box_loss: 0.0012 - val_reg_l2_loss: 0.0635 - val_loss: 0.3228\n",
            "Epoch 51/60\n",
            "21/21 [==============================] - 7s 354ms/step - det_loss: 0.3231 - cls_loss: 0.1999 - box_loss: 0.0025 - reg_l2_loss: 0.0635 - loss: 0.3866 - learning_rate: 2.5213e-04 - gradient_norm: 3.0049 - val_det_loss: 0.2648 - val_cls_loss: 0.2072 - val_box_loss: 0.0012 - val_reg_l2_loss: 0.0635 - val_loss: 0.3283\n",
            "Epoch 52/60\n",
            "21/21 [==============================] - 7s 356ms/step - det_loss: 0.4127 - cls_loss: 0.2532 - box_loss: 0.0032 - reg_l2_loss: 0.0635 - loss: 0.4762 - learning_rate: 1.9712e-04 - gradient_norm: 3.1802 - val_det_loss: 0.2720 - val_cls_loss: 0.2092 - val_box_loss: 0.0013 - val_reg_l2_loss: 0.0635 - val_loss: 0.3355\n",
            "Epoch 53/60\n",
            "21/21 [==============================] - 7s 353ms/step - det_loss: 0.3166 - cls_loss: 0.1972 - box_loss: 0.0024 - reg_l2_loss: 0.0635 - loss: 0.3801 - learning_rate: 1.4864e-04 - gradient_norm: 2.8574 - val_det_loss: 0.2737 - val_cls_loss: 0.2064 - val_box_loss: 0.0013 - val_reg_l2_loss: 0.0635 - val_loss: 0.3372\n",
            "Epoch 54/60\n",
            "21/21 [==============================] - 8s 377ms/step - det_loss: 0.3079 - cls_loss: 0.2023 - box_loss: 0.0021 - reg_l2_loss: 0.0635 - loss: 0.3714 - learning_rate: 1.0683e-04 - gradient_norm: 2.8604 - val_det_loss: 0.2697 - val_cls_loss: 0.2035 - val_box_loss: 0.0013 - val_reg_l2_loss: 0.0635 - val_loss: 0.3332\n",
            "Epoch 55/60\n",
            "21/21 [==============================] - 8s 389ms/step - det_loss: 0.3675 - cls_loss: 0.2363 - box_loss: 0.0026 - reg_l2_loss: 0.0635 - loss: 0.4310 - learning_rate: 7.1801e-05 - gradient_norm: 3.4696 - val_det_loss: 0.2694 - val_cls_loss: 0.2037 - val_box_loss: 0.0013 - val_reg_l2_loss: 0.0635 - val_loss: 0.3329\n",
            "Epoch 56/60\n",
            "21/21 [==============================] - 7s 350ms/step - det_loss: 0.3534 - cls_loss: 0.2258 - box_loss: 0.0026 - reg_l2_loss: 0.0635 - loss: 0.4169 - learning_rate: 4.3654e-05 - gradient_norm: 3.2959 - val_det_loss: 0.2677 - val_cls_loss: 0.2045 - val_box_loss: 0.0013 - val_reg_l2_loss: 0.0635 - val_loss: 0.3312\n",
            "Epoch 57/60\n",
            "21/21 [==============================] - 7s 360ms/step - det_loss: 0.3034 - cls_loss: 0.1963 - box_loss: 0.0021 - reg_l2_loss: 0.0635 - loss: 0.3669 - learning_rate: 2.2469e-05 - gradient_norm: 2.7251 - val_det_loss: 0.2698 - val_cls_loss: 0.2063 - val_box_loss: 0.0013 - val_reg_l2_loss: 0.0635 - val_loss: 0.3333\n",
            "Epoch 58/60\n",
            "21/21 [==============================] - 8s 377ms/step - det_loss: 0.2870 - cls_loss: 0.1772 - box_loss: 0.0022 - reg_l2_loss: 0.0635 - loss: 0.3505 - learning_rate: 8.3081e-06 - gradient_norm: 2.6367 - val_det_loss: 0.2683 - val_cls_loss: 0.2052 - val_box_loss: 0.0013 - val_reg_l2_loss: 0.0635 - val_loss: 0.3318\n",
            "Epoch 59/60\n",
            "21/21 [==============================] - 7s 356ms/step - det_loss: 0.3317 - cls_loss: 0.2077 - box_loss: 0.0025 - reg_l2_loss: 0.0635 - loss: 0.3952 - learning_rate: 1.2097e-06 - gradient_norm: 3.0792 - val_det_loss: 0.2686 - val_cls_loss: 0.2058 - val_box_loss: 0.0013 - val_reg_l2_loss: 0.0635 - val_loss: 0.3321\n",
            "Epoch 60/60\n",
            "21/21 [==============================] - 8s 387ms/step - det_loss: 0.3643 - cls_loss: 0.2175 - box_loss: 0.0029 - reg_l2_loss: 0.0635 - loss: 0.4278 - learning_rate: 1.1944e-06 - gradient_norm: 3.2441 - val_det_loss: 0.2689 - val_cls_loss: 0.2062 - val_box_loss: 0.0013 - val_reg_l2_loss: 0.0635 - val_loss: 0.3324\n"
          ]
        }
      ],
      "source": [
        "model = object_detector.create(train_data, model_spec=spec, batch_size=4, train_whole_model=True, epochs=60, validation_data=val_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KB4hKeerMmh4"
      },
      "source": [
        "### Step 4. Evaluate the model with the validation data.\n",
        "\n",
        "After training the object detection model using the images in the training dataset, use the 10 images in the validation dataset to evaluate how the model performs against new data it has never seen before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUqEpcYwAg8L",
        "outputId": "3014596d-782c-41c8-e95b-5ba0242bde29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/1 [==============================] - 4s 4s/step\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AP': 0.5719472,\n",
              " 'AP50': 0.8479491,\n",
              " 'AP75': 0.61103255,\n",
              " 'AP_/blue ball': 0.5972183,\n",
              " 'AP_/red ball': 0.5466761,\n",
              " 'APl': -1.0,\n",
              " 'APm': 0.772566,\n",
              " 'APs': 0.31732672,\n",
              " 'ARl': -1.0,\n",
              " 'ARm': 0.7916667,\n",
              " 'ARmax1': 0.4275,\n",
              " 'ARmax10': 0.62,\n",
              " 'ARmax100': 0.62,\n",
              " 'ARs': 0.4}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "model.evaluate(val_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NARVYk9rGLIl"
      },
      "source": [
        "### Step 5: Export as a TensorFlow Lite model.\n",
        "\n",
        "Export the trained object detection model to the TensorFlow Lite format by specifying which folder you want to export the quantized model to. The default post-training quantization technique is [full integer quantization](https://www.tensorflow.org/lite/performance/post_training_integer_quant). This allows the TensorFlow Lite model to be smaller, run faster on Raspberry Pi CPU and also compatible with the Google Coral EdgeTPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_u3eFxoBAiqE"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='.', tflite_filename='export.tflite')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZcBmEigOCO3"
      },
      "source": [
        "### Step 6:  Evaluate the TensorFlow Lite model.\n",
        "\n",
        "Several factors can affect the model accuracy when exporting to TFLite:\n",
        "* [Quantization](https://www.tensorflow.org/lite/performance/model_optimization) helps shrinking the model size by 4 times at the expense of some accuracy drop.\n",
        "* The original TensorFlow model uses per-class [non-max supression (NMS)](https://www.coursera.org/lecture/convolutional-neural-networks/non-max-suppression-dvrjH) for post-processing, while the TFLite model uses global NMS that's much faster but less accurate.\n",
        "Keras outputs maximum 100 detections while tflite outputs maximum 25 detections.\n",
        "\n",
        "Therefore you'll have to evaluate the exported TFLite model and compare its accuracy with the original TensorFlow model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jbl8z9_wBPlr",
        "outputId": "cf08ca50-3881-45de-90b8-d1aa0cc944e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 14s 3s/step\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AP': 0.5527503,\n",
              " 'AP50': 0.83223325,\n",
              " 'AP75': 0.55445546,\n",
              " 'AP_/blue ball': 0.5557756,\n",
              " 'AP_/red ball': 0.549725,\n",
              " 'APl': -1.0,\n",
              " 'APm': 0.7777228,\n",
              " 'APs': 0.26661953,\n",
              " 'ARl': -1.0,\n",
              " 'ARm': 0.8,\n",
              " 'ARmax1': 0.44,\n",
              " 'ARmax10': 0.5775,\n",
              " 'ARmax100': 0.5775,\n",
              " 'ARs': 0.3}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "model.evaluate_tflite('export.tflite', val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "v7zgUkdOUUnD",
        "outputId": "eecaba69-374c-462f-d1e7-6f30f4960125"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1f39ca0b-d094-4ab4-bcb8-46cf95a14a02\", \"60epoch.tflite\", 4444725)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Download the TFLite model to your local computer.\n",
        "from google.colab import files\n",
        "files.download('export.tflite')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnqktl45PZRy"
      },
      "source": [
        "## Test the Android figurine detection model\n",
        "\n",
        "After training the model, let's test it with an image that the model hasn't seen before to get a sense of how good the model is."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall opencv-python-headless\n",
        "!pip install opencv-python-headless==4.1.2.30\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "id": "FeNzIVZWzMmq",
        "outputId": "089e77aa-3b24-4a91-9b5d-d2aebc20f181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: opencv-python-headless 4.5.5.62\n",
            "Uninstalling opencv-python-headless-4.5.5.62:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/*\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless-4.5.5.62.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavcodec-64ac49e1.so.58.91.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavformat-4b79e479.so.58.45.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavutil-805734e8.so.56.51.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libbz2-a273e504.so.1.0.6\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libcrypto-018b8c17.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libgfortran-91cc3cb1.so.3.0.0\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libopenblas-r0-f650aae0.3.3.so\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libpng15-ce838cd1.so.15.13.0\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libquadmath-96973f99.so.0.0.0\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libssl-6082116c.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswresample-83ce3247.so.3.7.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswscale-7e960168.so.5.7.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libvpx-392cd848.so.6.4.0\n",
            "  Would not remove (might be manually added):\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtCore-bbdab771.so.4.8.7\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtGui-903938cd.so.4.8.7\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtTest-1183da5d.so.4.8.7\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavcodec-3cdd3bd4.so.58.62.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavformat-69a63b50.so.58.35.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavutil-8e8979a8.so.56.36.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libbz2-7225278b.so.1.0.3\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libcrypto-a25ff511.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libssl-fdf0b66c.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libswresample-c6b3bbb9.so.3.6.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libswscale-2d19f7d1.so.5.6.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libvpx-c887ea55.so.6.1.0\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libz-a147dcb0.so.1.2.3\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/cv2.cpython-37m-x86_64-linux-gnu.so\n",
            "Proceed (y/n)? t\n",
            "Your response ('t') was not one of the expected responses: y, n\n",
            "Proceed (y/n)? t\n",
            "Your response ('t') was not one of the expected responses: y, n\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled opencv-python-headless-4.5.5.62\n",
            "Collecting opencv-python-headless==4.1.2.30\n",
            "  Downloading opencv_python_headless-4.1.2.30-cp37-cp37m-manylinux1_x86_64.whl (21.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.8 MB 44.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.1.2.30) (1.21.5)\n",
            "Installing collected packages: opencv-python-headless\n",
            "Successfully installed opencv-python-headless-4.1.2.30\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cv2"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZsLQtJ1AlW_"
      },
      "outputs": [],
      "source": [
        "#@title Load the trained TFLite model and define some visualization functions\n",
        "\n",
        "#@markdown This code comes from the TFLite Object Detection [Raspberry Pi sample](https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/raspberry_pi).\n",
        "\n",
        "import platform\n",
        "from typing import List, NamedTuple\n",
        "import json\n",
        "\n",
        "import cv2\n",
        "\n",
        "Interpreter = tf.lite.Interpreter\n",
        "load_delegate = tf.lite.experimental.load_delegate\n",
        "\n",
        "# pylint: enable=g-import-not-at-top\n",
        "\n",
        "\n",
        "class ObjectDetectorOptions(NamedTuple):\n",
        "  \"\"\"A config to initialize an object detector.\"\"\"\n",
        "\n",
        "  enable_edgetpu: bool = False\n",
        "  \"\"\"Enable the model to run on EdgeTPU.\"\"\"\n",
        "\n",
        "  label_allow_list: List[str] = None\n",
        "  \"\"\"The optional allow list of labels.\"\"\"\n",
        "\n",
        "  label_deny_list: List[str] = None\n",
        "  \"\"\"The optional deny list of labels.\"\"\"\n",
        "\n",
        "  max_results: int = -1\n",
        "  \"\"\"The maximum number of top-scored detection results to return.\"\"\"\n",
        "\n",
        "  num_threads: int = 1\n",
        "  \"\"\"The number of CPU threads to be used.\"\"\"\n",
        "\n",
        "  score_threshold: float = 0.0\n",
        "  \"\"\"The score threshold of detection results to return.\"\"\"\n",
        "\n",
        "\n",
        "class Rect(NamedTuple):\n",
        "  \"\"\"A rectangle in 2D space.\"\"\"\n",
        "  left: float\n",
        "  top: float\n",
        "  right: float\n",
        "  bottom: float\n",
        "\n",
        "\n",
        "class Category(NamedTuple):\n",
        "  \"\"\"A result of a classification task.\"\"\"\n",
        "  label: str\n",
        "  score: float\n",
        "  index: int\n",
        "\n",
        "\n",
        "class Detection(NamedTuple):\n",
        "  \"\"\"A detected object as the result of an ObjectDetector.\"\"\"\n",
        "  bounding_box: Rect\n",
        "  categories: List[Category]\n",
        "\n",
        "\n",
        "def edgetpu_lib_name():\n",
        "  \"\"\"Returns the library name of EdgeTPU in the current platform.\"\"\"\n",
        "  return {\n",
        "      'Darwin': 'libedgetpu.1.dylib',\n",
        "      'Linux': 'libedgetpu.so.1',\n",
        "      'Windows': 'edgetpu.dll',\n",
        "  }.get(platform.system(), None)\n",
        "\n",
        "\n",
        "class ObjectDetector:\n",
        "  \"\"\"A wrapper class for a TFLite object detection model.\"\"\"\n",
        "\n",
        "  _OUTPUT_LOCATION_NAME = 'location'\n",
        "  _OUTPUT_CATEGORY_NAME = 'category'\n",
        "  _OUTPUT_SCORE_NAME = 'score'\n",
        "  _OUTPUT_NUMBER_NAME = 'number of detections'\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      model_path: str,\n",
        "      options: ObjectDetectorOptions = ObjectDetectorOptions()\n",
        "  ) -> None:\n",
        "    \"\"\"Initialize a TFLite object detection model.\n",
        "    Args:\n",
        "        model_path: Path to the TFLite model.\n",
        "        options: The config to initialize an object detector. (Optional)\n",
        "    Raises:\n",
        "        ValueError: If the TFLite model is invalid.\n",
        "        OSError: If the current OS isn't supported by EdgeTPU.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load metadata from model.\n",
        "    displayer = metadata.MetadataDisplayer.with_model_file(model_path)\n",
        "\n",
        "    # Save model metadata for preprocessing later.\n",
        "    model_metadata = json.loads(displayer.get_metadata_json())\n",
        "    process_units = model_metadata['subgraph_metadata'][0]['input_tensor_metadata'][0]['process_units']\n",
        "    mean = 0.0\n",
        "    std = 1.0\n",
        "    for option in process_units:\n",
        "      if option['options_type'] == 'NormalizationOptions':\n",
        "        mean = option['options']['mean'][0]\n",
        "        std = option['options']['std'][0]\n",
        "    self._mean = mean\n",
        "    self._std = std\n",
        "\n",
        "    # Load label list from metadata.\n",
        "    file_name = displayer.get_packed_associated_file_list()[0]\n",
        "    label_map_file = displayer.get_associated_file_buffer(file_name).decode()\n",
        "    label_list = list(filter(lambda x: len(x) > 0, label_map_file.splitlines()))\n",
        "    self._label_list = label_list\n",
        "\n",
        "    # Initialize TFLite model.\n",
        "    if options.enable_edgetpu:\n",
        "      if edgetpu_lib_name() is None:\n",
        "        raise OSError(\"The current OS isn't supported by Coral EdgeTPU.\")\n",
        "      interpreter = Interpreter(\n",
        "          model_path=model_path,\n",
        "          experimental_delegates=[load_delegate(edgetpu_lib_name())],\n",
        "          num_threads=options.num_threads)\n",
        "    else:\n",
        "      interpreter = Interpreter(\n",
        "          model_path=model_path, num_threads=options.num_threads)\n",
        "\n",
        "    interpreter.allocate_tensors()\n",
        "    input_detail = interpreter.get_input_details()[0]\n",
        "\n",
        "    # From TensorFlow 2.6, the order of the outputs become undefined.\n",
        "    # Therefore we need to sort the tensor indices of TFLite outputs and to know\n",
        "    # exactly the meaning of each output tensor. For example, if\n",
        "    # output indices are [601, 599, 598, 600], tensor names and indices aligned\n",
        "    # are:\n",
        "    #   - location: 598\n",
        "    #   - category: 599\n",
        "    #   - score: 600\n",
        "    #   - detection_count: 601\n",
        "    # because of the op's ports of TFLITE_DETECTION_POST_PROCESS\n",
        "    # (https://github.com/tensorflow/tensorflow/blob/a4fe268ea084e7d323133ed7b986e0ae259a2bc7/tensorflow/lite/kernels/detection_postprocess.cc#L47-L50).\n",
        "    sorted_output_indices = sorted(\n",
        "        [output['index'] for output in interpreter.get_output_details()])\n",
        "    self._output_indices = {\n",
        "        self._OUTPUT_LOCATION_NAME: sorted_output_indices[0],\n",
        "        self._OUTPUT_CATEGORY_NAME: sorted_output_indices[1],\n",
        "        self._OUTPUT_SCORE_NAME: sorted_output_indices[2],\n",
        "        self._OUTPUT_NUMBER_NAME: sorted_output_indices[3],\n",
        "    }\n",
        "\n",
        "    self._input_size = input_detail['shape'][2], input_detail['shape'][1]\n",
        "    self._is_quantized_input = input_detail['dtype'] == np.uint8\n",
        "    self._interpreter = interpreter\n",
        "    self._options = options\n",
        "\n",
        "  def detect(self, input_image: np.ndarray) -> List[Detection]:\n",
        "    \"\"\"Run detection on an input image.\n",
        "    Args:\n",
        "        input_image: A [height, width, 3] RGB image. Note that height and width\n",
        "          can be anything since the image will be immediately resized according\n",
        "          to the needs of the model within this function.\n",
        "    Returns:\n",
        "        A Person instance.\n",
        "    \"\"\"\n",
        "    image_height, image_width, _ = input_image.shape\n",
        "\n",
        "    input_tensor = self._preprocess(input_image)\n",
        "\n",
        "    self._set_input_tensor(input_tensor)\n",
        "    self._interpreter.invoke()\n",
        "\n",
        "    # Get all output details\n",
        "    boxes = self._get_output_tensor(self._OUTPUT_LOCATION_NAME)\n",
        "    classes = self._get_output_tensor(self._OUTPUT_CATEGORY_NAME)\n",
        "    scores = self._get_output_tensor(self._OUTPUT_SCORE_NAME)\n",
        "    count = int(self._get_output_tensor(self._OUTPUT_NUMBER_NAME))\n",
        "\n",
        "    return self._postprocess(boxes, classes, scores, count, image_width,\n",
        "                             image_height)\n",
        "\n",
        "  def _preprocess(self, input_image: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Preprocess the input image as required by the TFLite model.\"\"\"\n",
        "\n",
        "    # Resize the input\n",
        "    input_tensor = cv2.resize(input_image, self._input_size)\n",
        "\n",
        "    # Normalize the input if it's a float model (aka. not quantized)\n",
        "    if not self._is_quantized_input:\n",
        "      input_tensor = (np.float32(input_tensor) - self._mean) / self._std\n",
        "\n",
        "    # Add batch dimension\n",
        "    input_tensor = np.expand_dims(input_tensor, axis=0)\n",
        "\n",
        "    return input_tensor\n",
        "\n",
        "  def _set_input_tensor(self, image):\n",
        "    \"\"\"Sets the input tensor.\"\"\"\n",
        "    tensor_index = self._interpreter.get_input_details()[0]['index']\n",
        "    input_tensor = self._interpreter.tensor(tensor_index)()[0]\n",
        "    input_tensor[:, :] = image\n",
        "\n",
        "  def _get_output_tensor(self, name):\n",
        "    \"\"\"Returns the output tensor at the given index.\"\"\"\n",
        "    output_index = self._output_indices[name]\n",
        "    tensor = np.squeeze(self._interpreter.get_tensor(output_index))\n",
        "    return tensor\n",
        "\n",
        "  def _postprocess(self, boxes: np.ndarray, classes: np.ndarray,\n",
        "                   scores: np.ndarray, count: int, image_width: int,\n",
        "                   image_height: int) -> List[Detection]:\n",
        "    \"\"\"Post-process the output of TFLite model into a list of Detection objects.\n",
        "    Args:\n",
        "        boxes: Bounding boxes of detected objects from the TFLite model.\n",
        "        classes: Class index of the detected objects from the TFLite model.\n",
        "        scores: Confidence scores of the detected objects from the TFLite model.\n",
        "        count: Number of detected objects from the TFLite model.\n",
        "        image_width: Width of the input image.\n",
        "        image_height: Height of the input image.\n",
        "    Returns:\n",
        "        A list of Detection objects detected by the TFLite model.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    # Parse the model output into a list of Detection entities.\n",
        "    for i in range(count):\n",
        "      if scores[i] >= self._options.score_threshold:\n",
        "        y_min, x_min, y_max, x_max = boxes[i]\n",
        "        bounding_box = Rect(\n",
        "            top=int(y_min * image_height),\n",
        "            left=int(x_min * image_width),\n",
        "            bottom=int(y_max * image_height),\n",
        "            right=int(x_max * image_width))\n",
        "        class_id = int(classes[i])\n",
        "        category = Category(\n",
        "            score=scores[i],\n",
        "            label=self._label_list[class_id],  # 0 is reserved for background\n",
        "            index=class_id)\n",
        "        result = Detection(bounding_box=bounding_box, categories=[category])\n",
        "        results.append(result)\n",
        "\n",
        "    # Sort detection results by score ascending\n",
        "    sorted_results = sorted(\n",
        "        results,\n",
        "        key=lambda detection: detection.categories[0].score,\n",
        "        reverse=True)\n",
        "\n",
        "    # Filter out detections in deny list\n",
        "    filtered_results = sorted_results\n",
        "    if self._options.label_deny_list is not None:\n",
        "      filtered_results = list(\n",
        "          filter(\n",
        "              lambda detection: detection.categories[0].label not in self.\n",
        "              _options.label_deny_list, filtered_results))\n",
        "\n",
        "    # Keep only detections in allow list\n",
        "    if self._options.label_allow_list is not None:\n",
        "      filtered_results = list(\n",
        "          filter(\n",
        "              lambda detection: detection.categories[0].label in self._options.\n",
        "              label_allow_list, filtered_results))\n",
        "\n",
        "    # Only return maximum of max_results detection.\n",
        "    if self._options.max_results > 0:\n",
        "      result_count = min(len(filtered_results), self._options.max_results)\n",
        "      filtered_results = filtered_results[:result_count]\n",
        "\n",
        "    return filtered_results\n",
        "\n",
        "\n",
        "_MARGIN = 10  # pixels\n",
        "_ROW_SIZE = 10  # pixels\n",
        "_FONT_SIZE = 1\n",
        "_FONT_THICKNESS = 1\n",
        "_TEXT_COLOR = (0, 0, 255)  # red\n",
        "\n",
        "\n",
        "def visualize(\n",
        "    image: np.ndarray,\n",
        "    detections: List[Detection],\n",
        ") -> np.ndarray:\n",
        "  \"\"\"Draws bounding boxes on the input image and return it.\n",
        "  Args:\n",
        "    image: The input RGB image.\n",
        "    detections: The list of all \"Detection\" entities to be visualize.\n",
        "  Returns:\n",
        "    Image with bounding boxes.\n",
        "  \"\"\"\n",
        "  for detection in detections:\n",
        "    # Draw bounding_box\n",
        "    start_point = detection.bounding_box.left, detection.bounding_box.top\n",
        "    end_point = detection.bounding_box.right, detection.bounding_box.bottom\n",
        "    cv2.rectangle(image, start_point, end_point, _TEXT_COLOR, 3)\n",
        "\n",
        "    # Draw label and score\n",
        "    category = detection.categories[0]\n",
        "    class_name = category.label\n",
        "    probability = round(category.score, 2)\n",
        "    result_text = class_name + ' (' + str(probability) + ')'\n",
        "    text_location = (_MARGIN + detection.bounding_box.left,\n",
        "                     _MARGIN + _ROW_SIZE + detection.bounding_box.top)\n",
        "    cv2.putText(image, result_text, text_location, cv2.FONT_HERSHEY_PLAIN,\n",
        "                _FONT_SIZE, _TEXT_COLOR, _FONT_THICKNESS)\n",
        "\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "1t1z2fKlAoB0",
        "outputId": "6e26d856-2cf0-421a-9cce-9a6a0750e0ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=128x128 at 0x7F28DC56D510>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "#@title Run object detection and show the detection results\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "DETECTION_THRESHOLD = 0.3 #@param {type:\"number\"}\n",
        "TFLITE_MODEL_PATH = \"export.tflite\" #@param {type:\"string\"}\n",
        "\n",
        "image = Image.open('image_dir').convert('RGB')\n",
        "image.thumbnail((512, 512), Image.ANTIALIAS)\n",
        "image_np = np.asarray(image)\n",
        "\n",
        "# Load the TFLite model\n",
        "options = ObjectDetectorOptions(\n",
        "      num_threads=4,\n",
        "      score_threshold=DETECTION_THRESHOLD,\n",
        ")\n",
        "detector = ObjectDetector(model_path=TFLITE_MODEL_PATH, options=options)\n",
        "\n",
        "# Run object detection estimation using the model.\n",
        "detections = detector.detect(image_np)\n",
        "\n",
        "# Draw keypoints and edges on input image\n",
        "image_np = visualize(image_np, detections)\n",
        "\n",
        "# Show the detection result\n",
        "Image.fromarray(image_np)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWP3fEPaGNvd"
      },
      "source": [
        "## Compile the model for EdgeTPU\n",
        "\n",
        "Finally, we'll compile the model using `edgetpu_compiler` so that the model can run on [Google Coral EdgeTPU](https://coral.ai/).\n",
        "\n",
        "We start with installing the EdgeTPU compiler on Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kK6AN1xVAsCb",
        "outputId": "0a199dc3-a4df-4b4b-ef2b-b9d88b14cb53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2537  100  2537    0     0  59000      0 --:--:-- --:--:-- --:--:-- 59000\n",
            "OK\n",
            "deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:4 https://packages.cloud.google.com/apt coral-edgetpu-stable InRelease [6,722 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,398 kB]\n",
            "Ign:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Hit:13 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:14 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 Packages [2,327 B]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,434 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:17 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:18 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [786 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,810 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,835 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,213 kB]\n",
            "Get:24 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [927 kB]\n",
            "Get:25 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [44.7 kB]\n",
            "Fetched 12.8 MB in 3s (4,420 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  edgetpu-compiler\n",
            "0 upgraded, 1 newly installed, 0 to remove and 61 not upgraded.\n",
            "Need to get 7,913 kB of archives.\n",
            "After this operation, 31.2 MB of additional disk space will be used.\n",
            "Get:1 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 edgetpu-compiler amd64 16.0 [7,913 kB]\n",
            "Fetched 7,913 kB in 0s (20.6 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package edgetpu-compiler.\n",
            "(Reading database ... 155062 files and directories currently installed.)\n",
            "Preparing to unpack .../edgetpu-compiler_16.0_amd64.deb ...\n",
            "Unpacking edgetpu-compiler (16.0) ...\n",
            "Setting up edgetpu-compiler (16.0) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "!echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install edgetpu-compiler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIGSdzXkEzrj"
      },
      "source": [
        "**Note:** When training the model using a custom dataset, beware that if your dataset includes more than 20 classes, you'll probably have slower inference speeds compared to if you have fewer classes. This is due to an aspect of the EfficientDet architecture in which a certain layer cannot compile for the Edge TPU when it carries more than 20 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzF6u0FZTAjF"
      },
      "source": [
        "Before compiling the `.tflite` file for the Edge TPU, it's important to consider whether your model will fit into the Edge TPU memory. \n",
        "\n",
        "The Edge TPU has approximately 8 MB of SRAM for [caching model paramaters](https://coral.ai/docs/edgetpu/compiler/#parameter-data-caching), so any model close to or over 8 MB will not fit onto the Edge TPU memory. That means the inference times are longer, because some model parameters must be fetched from the host system memory.\n",
        "\n",
        "One way to elimiate the extra latency is to use [model pipelining](https://coral.ai/docs/edgetpu/pipeline/), which splits the model into segments that can run on separate Edge TPUs in series. This can significantly reduce the latency for big models.\n",
        "\n",
        "The following table provides recommendations for the number of Edge TPUs to use with each EfficientDet-Lite model.\n",
        "\n",
        "| Model architecture | Minimum TPUs | Recommended TPUs\n",
        "|--------------------|-------|-------|\n",
        "| EfficientDet-Lite0 | 1     | 1     |\n",
        "| EfficientDet-Lite1 | 1     | 1     |\n",
        "| EfficientDet-Lite2 | 1     | 2     |\n",
        "| EfficientDet-Lite3 | 2     | 2     |\n",
        "| EfficientDet-Lite4 | 2     | 3     |\n",
        "\n",
        "If you need extra Edge TPUs for your model, then update `NUMBER_OF_TPUS` here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyptUjakAwzz",
        "outputId": "7a3dad3b-eeb4-45e1-fb68-f0436ac5a933"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Edge TPU Compiler version 16.0.384591198\n",
            "Started a compilation timeout timer of 180 seconds.\n",
            "\n",
            "Model compiled successfully in 3127 ms.\n",
            "\n",
            "Input model: android.tflite\n",
            "Input size: 4.22MiB\n",
            "Output model: android_edgetpu.tflite\n",
            "Output size: 5.57MiB\n",
            "On-chip memory used for caching model parameters: 4.21MiB\n",
            "On-chip memory remaining for caching model parameters: 3.29MiB\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 267\n",
            "Operation log: android_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 264\n",
            "Number of operations that will run on CPU: 3\n",
            "See the operation log file for individual operation details.\n",
            "Compilation child process completed within timeout period.\n",
            "Compilation succeeded! \n"
          ]
        }
      ],
      "source": [
        "NUMBER_OF_TPUS = 1\n",
        "\n",
        "!edgetpu_compiler android.tflite --num_segments=$NUMBER_OF_TPUS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJYXucYWTGqZ"
      },
      "source": [
        "Finally, we'll copy the metadata, including the label file, from the original TensorFlow Lite model to the EdgeTPU model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LY1WrgMJBFd"
      },
      "outputs": [],
      "source": [
        "populator_dst = metadata.MetadataPopulator.with_model_file('android_edgetpu.tflite')\n",
        "\n",
        "with open('android.tflite', 'rb') as f:\n",
        "  populator_dst.load_metadata_and_associated_files(f.read())\n",
        "\n",
        "populator_dst.populate()\n",
        "updated_model_buf = populator_dst.get_model_buffer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "VdRihInCJ3ie",
        "outputId": "f2c37370-6ec3-41e6-903d-22e49e2f7dea"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_f466f03c-e5c8-4a91-a845-258a44b01400\", \"android_edgetpu.tflite\", 5844678)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Download the TFLite model compiled for EdgeTPU to your local computer.\n",
        "from google.colab import files\n",
        "files.download('android_edgetpu.tflite')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "EfficientDet",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}